{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from IPython import display\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from __future__ import division\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "filename = \"\"\n",
    "vp_table = np.zeros((2,10))\n",
    "fp_table = np.zeros((2,10))\n",
    "fn_table = np.zeros((2,10))\n",
    "vn_table = np.zeros((2,10))\n",
    "for i in range(10):\n",
    "    filename = 'DataBases/LBPTruncadoRaw'+str(i+1)+'.csv'\n",
    "    print \"Reading DataBase with partition: \"+str(i+1)\n",
    "    print filename\n",
    "    csv = np.genfromtxt (filename, delimiter=',')\n",
    "    \n",
    "    #balanced classes. For not balanced classes, select all the rows of the csv\n",
    "    Y = csv[350:,0]\n",
    "    X = csv[350:,1:]\n",
    "    \n",
    "    trainSize = 0.6\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=trainSize)\n",
    "    \n",
    "    #Dimensionality reduction step. If not desire, just comment out this block\n",
    "    clf = RandomForestClassifier()\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    X_train = model.transform(X_train)\n",
    "    X_test = model.transform(X_test)\n",
    "    \n",
    "    print \"Classifying with RandomForest\"\n",
    "    #train 5 random forest to avoid random noise\n",
    "    vn_aux = np.zeros(5)\n",
    "    vp_aux = np.zeros(5)\n",
    "    fp_aux = np.zeros(5)\n",
    "    fn_aux = np.zeros(5)\n",
    "    for j in range(5):\n",
    "        print \"Training Random Forest \"+str(j+1)\n",
    "        classifier = RandomForestClassifier(n_estimators=100, max_depth=None, class_weight='balanced')\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        print \"Computing confusion matrix\"\n",
    "        predicted_test_labels = classifier.predict_proba(X_test)[:,1]\n",
    "        [[VN,FP],[FN,VP]]=confusion_matrix(Y_test.astype(bool),(predicted_test_labels>0.5).astype(bool)).astype(float)\n",
    "        #save current confusion matrix of later use\n",
    "        vn_aux[j] = VN\n",
    "        vp_aux[j] = VP\n",
    "        fp_aux[j] = FP\n",
    "        fn_aux[j] = FN\n",
    "    print \"Saving classification data for the data base \"+str(i+1)\n",
    "    print \"\"\n",
    "    #save mean and std of confusion matrix\n",
    "    vn_table[0,i] = np.mean(vn_aux)#mean\n",
    "    vp_table[0,i] = np.mean(vp_aux)\n",
    "    fp_table[0,i] = np.mean(fp_aux)\n",
    "    fn_table[0,i] = np.mean(fn_aux)\n",
    "    \n",
    "    vn_table[1,i] = np.std(vn_aux)#desvest\n",
    "    vp_table[1,i] = np.std(vp_aux)\n",
    "    fp_table[1,i] = np.std(fp_aux)\n",
    "    fn_table[1,i] = np.std(fn_aux)\n",
    "    \n",
    "\n",
    "print \"Statistics: (mean and std)\"\n",
    "print \"\"\n",
    "print \"True positive\"\n",
    "print vp_table\n",
    "print \"True Negative\"\n",
    "print vn_table\n",
    "print \"False Positive\"\n",
    "print fp_table\n",
    "print \"False Negative\"\n",
    "print fn_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
